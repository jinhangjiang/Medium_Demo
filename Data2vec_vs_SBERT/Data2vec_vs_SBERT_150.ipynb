{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data2vec vs. SBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data2vec vs. SBERT\n",
        "https://www.kaggle.com/datasets/shivamkushwaha/bbc-full-text-document-classification"
      ],
      "metadata": {
        "id": "4yPYJzqecfzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers\n",
        "# !pip install sentence_transformers\n",
        "# !pip install scikit-learn-intelex\n",
        "# !pip3 install memory_profiler\n",
        "# "
      ],
      "metadata": {
        "id": "eYRNwnBd6E-t"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()\n",
        "%load_ext memory_profiler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgHcijyVB9AA",
        "outputId": "ee08ab6a-d5a6-4450-aab3-6eee035e5eaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/bbc-text.csv\")"
      ],
      "metadata": {
        "id": "B6vp41GfEzqw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.text.copy()\n",
        "y = df.category.copy()\n",
        "y = pd.factorize(y)[0]"
      ],
      "metadata": {
        "id": "z_-WOEnOJVqI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.category.unique())\n",
        "print(pd.factorize(y)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyJU8sR8PiBu",
        "outputId": "c1913d02-da2d-47ff-c544-dc2003fb453e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tech' 'business' 'sport' 'entertainment' 'politics']\n",
            "[0 1 2 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SBERT"
      ],
      "metadata": {
        "id": "ZXQHwXnCLCvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%memit\n",
        "model = SentenceTransformer('all-mpnet-base-v2',device='cuda')\n",
        "model.max_seq_length = 150\n",
        "\n",
        "\n",
        "#Sentences are encoded by calling model.encode()\n",
        "sentence_embeddings = X.apply(model.encode)\n",
        "sentence_embeddings = pd.DataFrame(sentence_embeddings.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jh2vD9WJ6-p",
        "outputId": "b4919c69-09f1-4acf-8e67-2fa0903b233c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 4549.16 MiB, increment: 3693.93 MiB\n",
            "CPU times: user 40.5 s, sys: 2.72 s, total: 43.2 s\n",
            "Wall time: 46.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings, y, test_size=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dq_nL9IML0g",
        "outputId": "ffbd2c46-a6ea-4570-bade-46cee8d3683f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11.5 ms, sys: 32 Âµs, total: 11.5 ms\n",
            "Wall time: 11.4 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(n_estimators=500).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ulhdCZWVPI7_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = rfc.predict(X_test)"
      ],
      "metadata": {
        "id": "JXmyb628SbjP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, prediction, target_names=df.category.unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykGYg3BuSgFv",
        "outputId": "e8070653-0b63-4219-9cdc-3511cdbdc290"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "         tech       0.96      0.97      0.97        78\n",
            "     business       0.97      0.95      0.96       116\n",
            "        sport       0.98      1.00      0.99       100\n",
            "entertainment       1.00      0.98      0.99        66\n",
            "     politics       0.94      0.95      0.95        85\n",
            "\n",
            "     accuracy                           0.97       445\n",
            "    macro avg       0.97      0.97      0.97       445\n",
            " weighted avg       0.97      0.97      0.97       445\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data2vec"
      ],
      "metadata": {
        "id": "8A1i8ih8TIYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%%memit\n",
        "#Mean Pooling - Take attention mask into account for correct averaging\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n",
        "\n",
        "\n",
        "#Load AutoModel from huggingface model repository\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/data2vec-text-base\")\n",
        "model = AutoModel.from_pretrained(\"facebook/data2vec-text-base\", num_labels = df.category.nunique()).to(\"cuda\")\n",
        "\n",
        "#Tokenize sentences\n",
        "encoded_input = tokenizer(list(X), padding=True, truncation=True, max_length=150, return_tensors='pt').to(\"cuda\")\n",
        "\n",
        "#Compute token embeddings\n",
        "with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "\n",
        "#Perform pooling. In this case, mean pooling\n",
        "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
        "sentence_embeddings = pd.DataFrame(sentence_embeddings.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xa4OVcxVS4V",
        "outputId": "79283512-3db4-47da-f3e8-e8c1931c920f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/data2vec-text-base were not used when initializing Data2VecTextModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing Data2VecTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Data2VecTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Data2VecTextModel were not initialized from the model checkpoint at facebook/data2vec-text-base and are newly initialized: ['data2vec_text.pooler.dense.weight', 'data2vec_text.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 4757.41 MiB, increment: 253.38 MiB\n",
            "CPU times: user 15.3 s, sys: 1.38 s, total: 16.7 s\n",
            "Wall time: 16.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings, y, test_size=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCRIfLZaYKSG",
        "outputId": "5212a86d-4078-45dc-97ce-547155ff7c76"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.5 ms, sys: 1.03 ms, total: 14.5 ms\n",
            "Wall time: 13.7 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier(n_estimators=500).fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "4rVhATKMbWeZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = rfc.predict(X_test)"
      ],
      "metadata": {
        "id": "rdVYOpsZbYe4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, prediction, target_names=df.category.unique()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7pj09oebazW",
        "outputId": "d746bdb7-c211-47aa-f791-68b18c7e1b25"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "         tech       0.88      0.85      0.87        81\n",
            "     business       0.84      0.87      0.85       107\n",
            "        sport       0.97      0.96      0.97       108\n",
            "entertainment       0.92      0.88      0.90        74\n",
            "     politics       0.82      0.85      0.84        75\n",
            "\n",
            "     accuracy                           0.89       445\n",
            "    macro avg       0.89      0.88      0.88       445\n",
            " weighted avg       0.89      0.89      0.89       445\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U_GecBOPPqwN"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}